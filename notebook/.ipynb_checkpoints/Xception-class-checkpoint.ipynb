{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196086\n",
      "(196299, 11)\n",
      "153730\n",
      "(153730, 10)\n"
     ]
    }
   ],
   "source": [
    "dataset_dir='/Disk4/xkp/dataset/iwilddata'\n",
    "root_dir='/Disk4/xkp/project/iwild'\n",
    "train_images_dir=dataset_dir+'/train_images'\n",
    "train_csv_path=dataset_dir+'/train.csv'\n",
    "test_images_dir=dataset_dir+'/test_images'\n",
    "test_csv_path=dataset_dir+'/test.csv'\n",
    "train_l=os.listdir(train_images_dir)\n",
    "print(len(train_l))\n",
    "train_df = pd.read_csv(train_csv_path,dtype = {'category_id': str})\n",
    "print(train_df.shape)\n",
    "\n",
    "test_l=os.listdir(test_images_dir)\n",
    "print(len(test_l))\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fce941c3cf8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.describe()\n",
    "import matplotlib.pyplot as plt\n",
    "train_df['category_id'] = train_df['category_id'].astype(str)\n",
    "h=train_df['category_id'].value_counts()\n",
    "\n",
    "print(h.dtypes)\n",
    "\n",
    "h.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is distribuation of classes for trainset\n",
    "### the train.csv contain (196299, 11) \n",
    "### the train_images contain 196086 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_num</th>\n",
       "      <th>location</th>\n",
       "      <th>seq_num_frames</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>153730.000000</td>\n",
       "      <td>153730.000000</td>\n",
       "      <td>153730.000000</td>\n",
       "      <td>153730.0</td>\n",
       "      <td>153730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.104703</td>\n",
       "      <td>49.227685</td>\n",
       "      <td>9.195915</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>586.839856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.441114</td>\n",
       "      <td>27.700477</td>\n",
       "      <td>10.155779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.423581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>645.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>726.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           frame_num       location  seq_num_frames     width         height\n",
       "count  153730.000000  153730.000000   153730.000000  153730.0  153730.000000\n",
       "mean        5.104703      49.227685        9.195915    1024.0     586.839856\n",
       "std         6.441114      27.700477       10.155779       0.0      64.423581\n",
       "min         1.000000       0.000000        1.000000    1024.0     544.000000\n",
       "25%         1.000000      24.000000        3.000000    1024.0     544.000000\n",
       "50%         3.000000      50.000000        6.000000    1024.0     544.000000\n",
       "75%         6.000000      74.000000       12.000000    1024.0     645.000000\n",
       "max        95.000000      99.000000       95.000000    1024.0     726.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n",
    "test_df.describe()\n",
    "\n",
    "# h_t=test_df['category_id'].value_counts()\n",
    "# print(h_t.dtypes)\n",
    "# h_t.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_num</th>\n",
       "      <th>location</th>\n",
       "      <th>seq_num_frames</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>196299.000000</td>\n",
       "      <td>196299.00000</td>\n",
       "      <td>196299.000000</td>\n",
       "      <td>196299.0</td>\n",
       "      <td>196299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.404047</td>\n",
       "      <td>65.83003</td>\n",
       "      <td>1.793494</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.486600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.739637</td>\n",
       "      <td>34.35272</td>\n",
       "      <td>1.026838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.128948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>96.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>138.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           frame_num      location  seq_num_frames     width         height\n",
       "count  196299.000000  196299.00000   196299.000000  196299.0  196299.000000\n",
       "mean        1.404047      65.83003        1.793494    1024.0     747.486600\n",
       "std         0.739637      34.35272        1.026838       0.0       3.128948\n",
       "min         1.000000       0.00000        1.000000    1024.0     747.000000\n",
       "25%         1.000000      30.00000        1.000000    1024.0     747.000000\n",
       "50%         1.000000      70.00000        1.000000    1024.0     747.000000\n",
       "75%         2.000000      96.00000        3.000000    1024.0     747.000000\n",
       "max         5.000000     138.00000        5.000000    1024.0     768.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 176478 images belonging to 14 classes.\n",
      "Found 19608 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "img_h,img_w=762//2,1024//2\n",
    "batch_size=16\n",
    "datagen = ImageDataGenerator(\n",
    "#     zca_whitening=True,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=1.0/255.0,\n",
    "    preprocessing_function=None,\n",
    "    validation_split=0.1)\n",
    "\n",
    "train_gen=datagen.flow_from_dataframe(\n",
    "        dataframe = train_df,        \n",
    "        directory = train_images_dir,\n",
    "        x_col = 'file_name', y_col = 'category_id',\n",
    "        target_size=(img_h,img_w),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "val_gen=datagen.flow_from_dataframe(\n",
    "        dataframe = train_df,        \n",
    "        directory = train_images_dir,\n",
    "        x_col = 'file_name', y_col = 'category_id',\n",
    "        target_size=(img_h,img_w),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0', '1', '10', '11', '13', '14', '16', '17', '18', '19', '22', '3', '4', '8'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname='Xception'\n",
    "modeldir=os.path.join(root_dir,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model=Xception(include_top=False,\n",
    "                  weights='imagenet', \n",
    "                  input_tensor=None, \n",
    "                  input_shape=(img_h,img_w,3),\n",
    "                  pooling='max',\n",
    "                  classes=1000)\n",
    "xception_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if not os.path.exists('cooper_xkp'):\n",
    "# #     os.mkdir('cooper_xkp/')\n",
    "# print(os.listdir('cooper_xkp/'))\n",
    "\n",
    "# with open('cooper_xkp/test.txt','w') as f:\n",
    "#     f.writelines('fasdfadfasdfasfdasfdadf')\n",
    "# with open('cooper_xkp/test.txt','r') as f:\n",
    "#     for line in f:\n",
    "#         print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(xception_model)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512,activation='relu',name='dense2048-512'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,activation='relu',name='dense512-128'))\n",
    "model.add(Dense(nb_classes,activation='softmax',name='out'))\n",
    "sgd=SGD(lr=0.001,decay=1e-4,momentum=0.9,nesterov=True)\n",
    "from keras.optimizers import Adam\n",
    "adam=Adam(lr=0.001,decay=0.0001)\n",
    "log_dir='log'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "modelcheck=ModelCheckpoint(filepath=modeldir+'/best-model.hdf5',monitor='val_loss',save_best_only=True,save_weights_only=True)\n",
    "csvlog=CSVLogger(filename=modeldir+'/csv_path.csv',separator=',',append=True)\n",
    "earstop=EarlyStopping(patience=15,monitor='val_loss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense2048-512 (Dense)        (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense512-128 (Dense)         (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 14)                1806      \n",
      "=================================================================\n",
      "Total params: 21,978,038\n",
      "Trainable params: 1,116,558\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy',f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---model weights load successfull---\n",
      "Epoch 1/50\n",
      "1102/1102 [==============================] - 991s 899ms/step - loss: 1.0650 - acc: 0.7122 - f1: 0.7086 - val_loss: 1.3233 - val_acc: 0.6875 - val_f1: 0.6898\n",
      "Epoch 2/50\n",
      "1102/1102 [==============================] - 986s 895ms/step - loss: 1.0383 - acc: 0.7141 - f1: 0.7138 - val_loss: 1.2649 - val_acc: 0.7292 - val_f1: 0.7267\n",
      "Epoch 3/50\n",
      "1102/1102 [==============================] - 979s 889ms/step - loss: 1.0125 - acc: 0.7191 - f1: 0.7155 - val_loss: 0.9892 - val_acc: 0.7708 - val_f1: 0.7908\n",
      "Epoch 4/50\n",
      "1102/1102 [==============================] - 973s 883ms/step - loss: 0.9838 - acc: 0.7220 - f1: 0.7240 - val_loss: 1.2112 - val_acc: 0.7083 - val_f1: 0.7104\n",
      "Epoch 5/50\n",
      "1102/1102 [==============================] - 972s 882ms/step - loss: 0.9548 - acc: 0.7311 - f1: 0.7322 - val_loss: 1.2483 - val_acc: 0.6771 - val_f1: 0.6638\n",
      "Epoch 6/50\n",
      "1102/1102 [==============================] - 981s 890ms/step - loss: 0.9562 - acc: 0.7273 - f1: 0.7310 - val_loss: 1.3043 - val_acc: 0.6771 - val_f1: 0.6763\n",
      "Epoch 7/50\n",
      "1102/1102 [==============================] - 985s 894ms/step - loss: 0.9581 - acc: 0.7293 - f1: 0.7289 - val_loss: 1.4921 - val_acc: 0.6979 - val_f1: 0.6846\n",
      "Epoch 8/50\n",
      "1102/1102 [==============================] - 982s 891ms/step - loss: 0.9366 - acc: 0.7312 - f1: 0.7353 - val_loss: 0.9703 - val_acc: 0.7396 - val_f1: 0.7533\n",
      "Epoch 9/50\n",
      "1102/1102 [==============================] - 983s 892ms/step - loss: 0.9270 - acc: 0.7345 - f1: 0.7349 - val_loss: 0.9582 - val_acc: 0.7500 - val_f1: 0.7321\n",
      "Epoch 10/50\n",
      "1102/1102 [==============================] - 982s 891ms/step - loss: 0.9030 - acc: 0.7406 - f1: 0.7426 - val_loss: 1.3663 - val_acc: 0.6458 - val_f1: 0.6543\n",
      "Epoch 11/50\n",
      "1102/1102 [==============================] - 830s 753ms/step - loss: 0.9061 - acc: 0.7362 - f1: 0.7405 - val_loss: 1.4641 - val_acc: 0.6875 - val_f1: 0.7006\n",
      "Epoch 12/50\n",
      "1102/1102 [==============================] - 830s 753ms/step - loss: 0.8927 - acc: 0.7477 - f1: 0.7473 - val_loss: 1.3255 - val_acc: 0.6667 - val_f1: 0.6706\n",
      "Epoch 13/50\n",
      "1102/1102 [==============================] - 837s 759ms/step - loss: 0.9092 - acc: 0.7371 - f1: 0.7382 - val_loss: 1.0388 - val_acc: 0.7292 - val_f1: 0.7243\n",
      "Epoch 14/50\n",
      "1102/1102 [==============================] - 848s 770ms/step - loss: 0.9042 - acc: 0.7406 - f1: 0.7422 - val_loss: 1.1092 - val_acc: 0.6979 - val_f1: 0.7132\n",
      "Epoch 15/50\n",
      "1102/1102 [==============================] - 861s 781ms/step - loss: 0.9025 - acc: 0.7335 - f1: 0.7397 - val_loss: 0.9735 - val_acc: 0.7708 - val_f1: 0.7760\n",
      "Epoch 16/50\n",
      "1102/1102 [==============================] - 883s 802ms/step - loss: 0.9080 - acc: 0.7371 - f1: 0.7398 - val_loss: 1.1228 - val_acc: 0.6875 - val_f1: 0.7162\n",
      "CPU times: user 3h 32min 57s, sys: 6min, total: 3h 38min 57s\n",
      "Wall time: 4h 8min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model\n",
    "nb_epochs=50\n",
    "model.load_weights(log_dir+'/best-model.hdf5')\n",
    "print('---model weights load successfull---')\n",
    "history = model.fit_generator(\n",
    "            train_gen,\n",
    "            steps_per_epoch = (train_gen.samples // batch_size)//10,\n",
    "#           steps_per_epoch = 100,\n",
    "            validation_data = val_gen, \n",
    "            validation_steps = (val_gen.samples // batch_size)//200,\n",
    "#           validation_steps = 50,\n",
    "            epochs = nb_epochs,\n",
    "            callbacks=[modelcheck,csvlog,earstop],\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153730 images.\n",
      "CPU times: user 683 ms, sys: 324 ms, total: 1.01 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe = test_df,        \n",
    "        directory = test_images_dir,\n",
    "        x_col = 'file_name', y_col = None,\n",
    "        target_size = (img_h,img_w),\n",
    "        batch_size = 10,\n",
    "        shuffle = False,\n",
    "        class_mode = None\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  338/15373 [..............................] - ETA: 1:31:25"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_generator.reset()\n",
    "predict = model.predict_generator(test_generator, steps = len(test_generator.filenames)/10,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(predict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_gen.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_sub_df = pd.read_csv(dataset_dir+'/sample_submission.csv')\n",
    "print(sam_sub_df.shape)\n",
    "sam_sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Id\":filenames,\n",
    "                      \"Predicted\":predictions})\n",
    "s=time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime()) \n",
    "results['Id'] = results['Id'].map(lambda x: str(x)[:-4])\n",
    "results.to_csv(model_dir+'/'+s+\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
