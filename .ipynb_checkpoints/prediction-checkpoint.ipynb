{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Disk4/xkp/dataset/iwilddata/train.csv\n",
      "train length 196086\n",
      "(196299, 11)\n",
      "153730\n",
      "(153730, 10)\n",
      "int64\n",
      "           frame_num       location  seq_num_frames     width         height\n",
      "count  153730.000000  153730.000000   153730.000000  153730.0  153730.000000\n",
      "mean        5.104703      49.227685        9.195915    1024.0     586.839856\n",
      "std         6.441114      27.700477       10.155779       0.0      64.423581\n",
      "min         1.000000       0.000000        1.000000    1024.0     544.000000\n",
      "25%         1.000000      24.000000        3.000000    1024.0     544.000000\n",
      "50%         3.000000      50.000000        6.000000    1024.0     544.000000\n",
      "75%         6.000000      74.000000       12.000000    1024.0     645.000000\n",
      "max        95.000000      99.000000       95.000000    1024.0     726.000000\n",
      "           frame_num      location  seq_num_frames     width         height\n",
      "count  196299.000000  196299.00000   196299.000000  196299.0  196299.000000\n",
      "mean        1.404047      65.83003        1.793494    1024.0     747.486600\n",
      "std         0.739637      34.35272        1.026838       0.0       3.128948\n",
      "min         1.000000       0.00000        1.000000    1024.0     747.000000\n",
      "25%         1.000000      30.00000        1.000000    1024.0     747.000000\n",
      "50%         1.000000      70.00000        1.000000    1024.0     747.000000\n",
      "75%         2.000000      96.00000        3.000000    1024.0     747.000000\n",
      "max         5.000000     138.00000        5.000000    1024.0     768.000000\n",
      "Found 176478 images belonging to 14 classes.\n",
      "Found 19608 images belonging to 14 classes.\n",
      "{'18', '1', '11', '13', '0', '17', '10', '16', '19', '22', '3', '4', '8', '14'}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense2048-512 (Dense)        (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense512-128 (Dense)         (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 14)                1806      \n",
      "_________________________________________________________________\n",
      "mylayer_3 (MYLAYER)          (None, 14)                2         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 21,980,088\n",
      "Trainable params: 1,117,584\n",
      "Non-trainable params: 20,862,504\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense2048-512 (Dense)        (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense512-128 (Dense)         (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 14)                1806      \n",
      "_________________________________________________________________\n",
      "mylayer_3 (MYLAYER)          (None, 14)                2         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 21,980,088\n",
      "Trainable params: 1,117,584\n",
      "Non-trainable params: 20,862,504\n",
      "_________________________________________________________________\n",
      "---model weights load successfull---\n",
      "---/Disk4/xkp/project/sjwl_xxxx/modelinfo/Xception/weights/02-0.82-1.02.h5---\n",
      "Found 153730 images.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "np.random.seed(2019)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "set_session(tf.Session(config=config))\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.xception import Xception\n",
    "from utils.losses import categorical_crossentropy\n",
    "from utils.Mertics import f1\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,CSVLogger\n",
    "from models.Xception_Classification import XceptionClass\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import Adam\n",
    "from utils.CallBacks import *\n",
    "import utils.config\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from utils.ImageAugementation import function_line\n",
    "from utils.config import config\n",
    "from utils.config import config\n",
    "\n",
    "modeldict=config.modeldict\n",
    "\n",
    "\n",
    "\n",
    "train_images_dir=config.train_images_dir\n",
    "\n",
    "dataset_dir=config.dataset_dir\n",
    "\n",
    "root_dir=config.root_dir\n",
    "\n",
    "train_csv_path=config.train_csv_path\n",
    "print(train_csv_path)\n",
    "\n",
    "test_images_dir=config.test_images_dir\n",
    "\n",
    "test_csv_path=config.test_csv_path\n",
    "\n",
    "num_gpu=config.num_gpu\n",
    "\n",
    "droprate=config.droprate\n",
    "\n",
    "kernel_re=config.kernel_re\n",
    "\n",
    "img_h,img_w=config.img_h,config.img_w\n",
    "\n",
    "batch_size=config.batch_size\n",
    "\n",
    "modelname=config.modelname\n",
    "\n",
    "weightsname='02-0.82-1.02.h5'\n",
    "\n",
    "nb_classes =config.nb_classes\n",
    "\n",
    "lr=config.lr\n",
    "\n",
    "tensorboarddir='logs'\n",
    "modeldir=os.path.join(root_dir,'modelinfo',modelname)\n",
    "if not os.path.exists(root_dir+'/modelinfo'):\n",
    "    os.mkdir(root_dir+'/modelinfo')\n",
    "if not os.path.exists(modeldir):\n",
    "    os.mkdir(modeldir)\n",
    "if not os.path.exists(modeldir+'/'+'weights'):\n",
    "    os.mkdir(modeldir+'/'+'weights')\n",
    "if not os.path.exists(modeldir+'/'+tensorboarddir):\n",
    "    os.mkdir(modeldir+'/'+tensorboarddir)\n",
    "\n",
    "\n",
    "train_l=os.listdir(train_images_dir)\n",
    "print('train length',len(train_l))\n",
    "train_df = pd.read_csv(train_csv_path,dtype = {'category_id': str})\n",
    "print(train_df.shape)\n",
    "\n",
    "test_l=os.listdir(test_images_dir)\n",
    "print(len(test_l))\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "print(test_df.shape)\n",
    "train_df.describe()\n",
    "train_df['category_id'] = train_df['category_id'].astype(str)\n",
    "h=train_df['category_id'].value_counts()\n",
    "\n",
    "print(h.dtypes)\n",
    "\n",
    "# h.plot(kind='bar')\n",
    "\n",
    "test_df.head()\n",
    "print(test_df.describe())\n",
    "train_df.head()\n",
    "print(train_df.describe())\n",
    "\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "#     zca_whitening=True,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=1.0/255.0,\n",
    "    preprocessing_function=None,\n",
    "    validation_split=0.1)\n",
    "\n",
    "train_gen=datagen.flow_from_dataframe(\n",
    "        dataframe = train_df,\n",
    "        directory = train_images_dir,\n",
    "        x_col = 'file_name', y_col = 'category_id',\n",
    "        target_size=(img_h,img_w),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "val_gen=datagen.flow_from_dataframe(\n",
    "        dataframe = train_df,\n",
    "        directory = train_images_dir,\n",
    "        x_col = 'file_name', y_col = 'category_id',\n",
    "        target_size=(img_h,img_w),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "\n",
    "\n",
    "# print(set(train_gen.class_indices))\n",
    "print(train_gen.class_indices)\n",
    "if modelname not in modeldict.keys():\n",
    "    print('---The '+modelname+'have not defined in modeldict ---')\n",
    "    os._exists(0)\n",
    "\n",
    "model=modeldict[modelname](input_shape=(img_h,img_w,3),classes=nb_classes,droprate=droprate,kernel_regu_rate=kernel_re)\n",
    "\n",
    "# if num_gpu>1:\n",
    "#     model=multi_gpu_model(model,num_gpu)\n",
    "\n",
    "sgd=SGD(lr=lr,decay=1e-3,momentum=0.9,nesterov=True)\n",
    "\n",
    "adam=Adam(lr=lr,decay=0.0001)\n",
    "\n",
    "modelcheck=ModelCheckpoint(filepath=modeldir+'/'+'weights'+'/{epoch:02d}-{val_loss:.2f}-{loss:.2f}.h5',monitor='val_loss',save_weights_only=True)\n",
    "csvlog=CSVLogger(filename=modeldir+'/csv_path.csv',separator=',',append=True)\n",
    "earstop=EarlyStopping(patience=15,monitor='val_loss')\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy',f1])\n",
    "\n",
    "\n",
    "\n",
    "# Train model\n",
    "nb_epochs=config.nb_epochs\n",
    "\n",
    "if os.path.exists(modeldir+'/'+'weights'+'/'+str(weightsname)) and (not weightsname==None):\n",
    "    model.load_weights(modeldir+'/'+'weights'+'/'+weightsname)\n",
    "    print('---model weights load successfull---')\n",
    "    print('---'+modeldir+'/'+'weights'+'/'+weightsname+'---')\n",
    "else:\n",
    "    print('----------not load weihts!!!!!!!!!-----------')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe = test_df,\n",
    "        directory = test_images_dir,\n",
    "        x_col = 'file_name', y_col = None,\n",
    "        target_size = (img_h,img_w),\n",
    "        batch_size = 10,\n",
    "        shuffle = False,\n",
    "        class_mode = None\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "predict = model.predict_generator(test_generator, steps = len(test_generator.filenames)/10,verbose=1,workers=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(predict,axis=1)\n",
    "labels = (train_gen.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "sam_sub_df = pd.read_csv(dataset_dir+'/sample_submission.csv')\n",
    "print(sam_sub_df.shape)\n",
    "sam_sub_df.head()\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Id\":filenames,\n",
    "                      \"Predicted\":predictions})\n",
    "s=time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "results['Id'] = results['Id'].map(lambda x: str(x)[:-4])\n",
    "results.to_csv(modeldir+'/'+s+\"-results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
